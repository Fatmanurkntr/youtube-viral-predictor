{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d28ba8c",
   "metadata": {},
   "source": [
    "## Feature Engineering Amacı ve Stratejisi\n",
    "\n",
    "Bu aşamanın temel amacı, Baseline modelin çözemediği doğrusal olmayan ilişkileri (saat, kategori, başlık içeriği) çözmek için modelin anlayacağı **yeni sayısal özellikler** (features) türetmektir. Türetilen bu yeni özellikler, R2 skorunu Baseline'ın (**0.6509**) üzerine çıkarmayı hedeflemektedir. Model seçimimiz, Baseline kıyaslaması sonucunda daha başarılı olduğu kanıtlanan **ağaç tabanlı (tree-based)** modellere odaklanacaktır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9171e77a",
   "metadata": {},
   "source": [
    "## Adım 1: Veri Yükleme ve Zamanlama Özellikleri\n",
    "Bu kod bloğu, veriyi yükler, gerekli temizliği yapar ve en temel özellik setimiz olan Zamanlama Özelliklerini (Ne zaman yayınlanmalı?) türetir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39726e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zamanlama Özellikleri Türetildi.\n",
      "Yeni Sütunlar: publish_hour, publish_day, is_weekend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. VERİYİ YÜKLEME VE TEMİZLİK\n",
    "try:\n",
    "    df = pd.read_csv('../data/US_youtube_trending_data.csv', encoding='utf-8')\n",
    "except Exception:\n",
    "    df = pd.read_csv('../data/US_youtube_trending_data.csv', encoding='latin1')\n",
    "\n",
    "# Log dönüşümü için 0 olan değerleri temizliyoruz\n",
    "df = df[(df['view_count'] > 0) & (df['likes'] > 0)].copy()\n",
    "\n",
    "# 2. ZAMANLAMA ÖZELLİKLERİNİ TÜRETME\n",
    "df['publishedAt'] = pd.to_datetime(df['publishedAt'])\n",
    "\n",
    "# A) Yayın Saati (publish_hour)\n",
    "df['publish_hour'] = df['publishedAt'].dt.hour \n",
    "\n",
    "# B) Yayın Günü (publish_day)\n",
    "df['publish_day'] = df['publishedAt'].dt.day_name() \n",
    "\n",
    "# C) Haftasonu mu? (Boolean/Sayısal)\n",
    "df['is_weekend'] = df['publishedAt'].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "print(\"✅ Zamanlama Özellikleri Türetildi.\")\n",
    "print(f\"Yeni Sütunlar: publish_hour, publish_day, is_weekend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e7b3b",
   "metadata": {},
   "source": [
    "### Kategorik Özellik Haritalaması (JSON Mapping)\n",
    "Kullanılan veri setinde video kategorileri sayısal ID'ler (Örn: 24, 10) olarak yer almaktadır. Bu sayısal ID'leri analizlerde anlamlılık katması için dışarıdan okunan JSON dosyası ile eşleştirilerek okunabilir kategori isimlerine (`category_name` sütununa) çevrilmiştir. Bu, modelin \"Hangi kategoride yayınlanmalı?\" sorusunu çözerken, sayılar yerine anlamlı etiketleri kullanmasını sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5bbe2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kategori İsimleri Haritalandı.\n"
     ]
    }
   ],
   "source": [
    "# --- EK KATEGORİ HARİTALAMA VE EŞLEŞTİRME ---\n",
    "import json\n",
    "\n",
    "# Kategori İsimlerini JSON dosyasından çekip eşleştiriyoruz\n",
    "id_to_category = {}\n",
    "try:\n",
    "    with open('../data/US_category_id.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for category in data['items']:\n",
    "            id_to_category[int(category['id'])] = category['snippet']['title']\n",
    "    \n",
    "    # 'categoryId' sütununu isimlerle değiştiriyoruz\n",
    "    df['category_name'] = df['categoryId'].map(id_to_category)\n",
    "    print(\"✅ Kategori İsimleri Haritalandı.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ UYARI: JSON dosyası bulunamadı, kategoriler isme çevrilemedi.\")\n",
    "except KeyError as e:\n",
    "    # Bu hata, categoryId sütununun adının farklı olmasından kaynaklanabilir.\n",
    "    print(f\"⚠️ UYARI: Kategori haritalaması başarısız oldu: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62129c4",
   "metadata": {},
   "source": [
    "## Adım 2: Metin ve Etiket Özellikleri\n",
    "Bu adım, modelin \"Ne tür içerik trend oluyor?\" sorusunu çözmesini sağlayacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1154016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metin ve Etiket Özellikleri Türetildi.\n",
      "Yeni Sütunlar: title_length, tag_count, has_exclamation, has_question\n"
     ]
    }
   ],
   "source": [
    "# --- 3. METİN VE ETİKET ÖZELLİKLERİNİ TÜRETME ---\n",
    "\n",
    "# A) Başlık Uzunluğu (Title Length)\n",
    "df['title_length'] = df['title'].str.len()\n",
    "\n",
    "# B) Etiket Sayısı (Tag Count)\n",
    "# Tags sütunu string olduğu için '|' karakterine göre ayırıp sayıyoruz.\n",
    "df['tag_count'] = df['tags'].apply(lambda x: 0 if x == '[none]' else len(x.split('|')))\n",
    "\n",
    "# C) Noktalama İşaretleri (Başlık Psikolojisi)\n",
    "# EDA'da görmüştük: Ünlem ve soru işareti izlenmeyi etkiliyor.\n",
    "df['has_exclamation'] = df['title'].apply(lambda x: 1 if '!' in str(x) else 0)\n",
    "df['has_question'] = df['title'].apply(lambda x: 1 if '?' in str(x) else 0)\n",
    "\n",
    "print(\"✅ Metin ve Etiket Özellikleri Türetildi.\")\n",
    "print(f\"Yeni Sütunlar: title_length, tag_count, has_exclamation, has_question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbafb96",
   "metadata": {},
   "source": [
    "###  Türetilmiş Özellikler Raporu (Temporal & Textual)\n",
    "\n",
    "**1. Zamanlama Özellikleri:** `publish_hour`, `publish_day` ve `is_weekend` gibi özellikler türetilerek Baseline modelin çözemediği **zamana bağlı trend döngüsü** analizi için hazırlanmıştır.\n",
    "\n",
    "**2. Metin ve Etiket Özellikleri:** Başlık uzunluğu, etiket sayısı ve noktalama işaretleri gibi özellikler türetilerek, **içerik türünün ve başlık stratejisinin** izlenme üzerindeki doğrusal olmayan etkileri ölçülmeye hazır hale getirilmiştir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d176af",
   "metadata": {},
   "source": [
    "## Adım 3: Kategorik Kodlama (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f40cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Kategorik Kodlama Başarılı.\n",
      "Yeni Toplam Özellik Sayısı: 33 adet\n",
      "\n",
      "--- SON ÖZELLİK LİSTESİ (MODEL GİRDİSİ) ---\n",
      "['categoryId', 'view_count', 'likes', 'dislikes', 'comment_count', 'comments_disabled', 'ratings_disabled', 'publish_hour', 'is_weekend', 'title_length', 'tag_count', 'has_exclamation', 'has_question', 'category_name_Comedy', 'category_name_Education', 'category_name_Entertainment', 'category_name_Film & Animation', 'category_name_Gaming', 'category_name_Howto & Style', 'category_name_Music', 'category_name_News & Politics', 'category_name_Nonprofits & Activism', 'category_name_People & Blogs', 'category_name_Pets & Animals', 'category_name_Science & Technology', 'category_name_Sports', 'category_name_Travel & Events', 'publish_day_Monday', 'publish_day_Saturday', 'publish_day_Sunday', 'publish_day_Thursday', 'publish_day_Tuesday', 'publish_day_Wednesday']\n"
     ]
    }
   ],
   "source": [
    "# --- KATEGORİK KODLAMA (ONE-HOT ENCODING) ve SÜTUNLARI TEMİZLEME ---\n",
    "\n",
    "# Kategorik olarak kullanacağımız sütunlar\n",
    "categorical_features = ['category_name', 'publish_day'] \n",
    "\n",
    "# One-Hot Encoding uygulama\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Fazla detayı olan ve model için uygun olmayan ham sütunları atıyoruz\n",
    "cols_to_drop = [\n",
    "    'video_id', \n",
    "    'title', \n",
    "    'channelTitle', \n",
    "    'tags', \n",
    "    'publishedAt', \n",
    "    'trending_date', \n",
    "    'description', \n",
    "    'channelId',\n",
    "    'thumbnail_link'\n",
    "]\n",
    "\n",
    "df_final = df_encoded.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "print(\"✅ Kategorik Kodlama Başarılı.\")\n",
    "print(f\"Yeni Toplam Özellik Sayısı: {df_final.shape[1]} adet\")\n",
    "\n",
    "# BU SATIR, 35+ SÜTUNUN TAM LİSTESİNİ ÇIKTIDA GÖSTERİR\n",
    "print(\"\\n--- SON ÖZELLİK LİSTESİ (MODEL GİRDİSİ) ---\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a271878",
   "metadata": {},
   "source": [
    "###  Final Feature Set Raporu\n",
    "\n",
    "**1. Başarı:** Ham sayısal özellik sayısı 2 iken, Zaman, Metin ve Kategorik analizler sonucunda toplam **33 türetilmiş özellik** içeren final bir set oluşturulmuştur. Bu, modelin Baseline modelde çözemediği **%35.84'lük varyansı** çözmek için gerekli tüm bilgileri içerdiğini gösterir.\n",
    "\n",
    "**2. Amaç:** Bu yeni özellik seti, Baseline skorumuz olan **0.6509**'un üzerine çıkmak için hazırlanmıştır. Model, artık sadece beğeniye değil, aynı zamanda 33 farklı zamansal, metinsel ve kategorik faktöre bakarak tahmin yapacaktır.\n",
    "\n",
    "**3. Karar:** Özellik sayımız ($N=33$) yüksek olduğu için, modelin hızını ve doğruluğunu artırmak amacıyla eğitime geçmeden önce **Feature Selection (Özellik Seçimi)** uygulanacaktır. Veri setimiz artık **ağaç tabanlı (XGBoost/Random Forest)** modellerle eğitime tamamen hazırdır."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3365c6",
   "metadata": {},
   "source": [
    "## Adım 4: Feature Selection (Özellik Seçimi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c516132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fatmanur\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature Selection Tamamlandı.\n",
      "Başlangıç Özellik Sayısı: 32\n",
      "Seçilen Özellik Sayısı: 5\n",
      "\n",
      "--- Seçilen En Önemli Özellikler ---\n",
      "['likes', 'dislikes', 'comment_count', 'title_length', 'tag_count']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# --- 1. VERİ AYARLAMA ---\n",
    "# Hedef değişkeni (Y) logaritma ile hazırlıyoruz\n",
    "y_target = np.log1p(df_final['view_count']) \n",
    "\n",
    "# Özellikleri (X) ayırıyoruz ('view_count' hedef olduğu için çıkarıldı)\n",
    "X_features = df_final.drop(columns=['view_count']) \n",
    "\n",
    "# Veriyi bölüyoruz (Sadece SelectFromModel için train/test gerekli)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 2. RANDOM FOREST İLE ÖNEM SIRASINI BELİRLEME\n",
    "# RFR, her özelliğin modele ne kadar katkı sağladığını ölçer\n",
    "model_selector = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model_selector.fit(X_train, y_train)\n",
    "\n",
    "# 3. ÖNEMLİ ÖZELLİKLERİ SEÇME\n",
    "# Eşiği, ortalama önem değerinin üstüne koyarak seçimi daraltıyoruz.\n",
    "# SelectFromModel, Random Forest'ın önem skorlarına göre otomatik seçim yapar.\n",
    "sfm = SelectFromModel(model_selector, threshold='mean', prefit=True)\n",
    "\n",
    "# Seçilen sütunları bulma\n",
    "X_important = sfm.transform(X_features)\n",
    "selected_features_mask = sfm.get_support()\n",
    "selected_features = X_features.columns[selected_features_mask].tolist()\n",
    "\n",
    "print(\"✅ Feature Selection Tamamlandı.\")\n",
    "print(f\"Başlangıç Özellik Sayısı: {X_features.shape[1]}\")\n",
    "print(f\"Seçilen Özellik Sayısı: {len(selected_features)}\")\n",
    "print(\"\\n--- Seçilen En Önemli Özellikler ---\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932f94c6",
   "metadata": {},
   "source": [
    "###  Nihai Feature Engineering Sonucu\n",
    "\n",
    "**1. Özellik Azaltımı:** Başlangıçtaki 33 özellikten, Random Forest (RFR) algoritması kullanılarak en güçlü ve modele en çok katkı sağlayan **sadece 5 adet özellik** seçilmiştir.\n",
    "\n",
    "**2. Seçilen Özellikler:** Modelin başarısının temelini **Etkileşim Metrikleri** (`likes`, `comment_count`, `dislikes`) oluşturmaktadır. Bunların yanına, en güçlü türetilmiş özellikler olan **`title_length`** ve **`tag_count`** eklenmiştir. Bu durum, model için **saat veya gün** gibi özelliklerin, temel etkileşim verileri kadar kritik olmadığını kanıtlamaktadır.\n",
    "\n",
    "**3. Amaç:** Bu agresif azaltım, projenin final modelinin (XGBoost) eğitim süresini hızlandırmak ve alakasız 28 özelliğin modelin tahmin doğruluğunu düşürmesini engellemeyi amaçlar. **Final modelimiz, Baseline'ın 0.6509 R2 skorunu geçmek zorundadır.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
